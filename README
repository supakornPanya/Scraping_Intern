# CEDT Intern Scraping Project

Web scraping ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å CEDT Intern System

## üìã Project Overview

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:
1. **Scraping ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å CEDT Intern API
2. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** - ‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
3. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥** - Bookmark ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ú‡πà‡∏≤‡∏ô API

## üóÇÔ∏è File Structure

```
Scraping_Intern/
‚îú‚îÄ‚îÄ scraping_intern_Paginated.ipynb      # Scraping ‡πÅ‡∏ö‡∏ö pagination
‚îú‚îÄ‚îÄ scraping_intern_DetailPosition.ipynb # Scraping ‡πÅ‡∏ö‡∏ö detail position
‚îú‚îÄ‚îÄ clean_data.ipynb                     # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‚îú‚îÄ‚îÄ slect_position.ipynb                 # Bookmark ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
‚îú‚îÄ‚îÄ cedt_intern_data_paginated13.csv     # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å pagination
‚îú‚îÄ‚îÄ cedt_intern_data_1000_2000.csv       # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å detail position
‚îú‚îÄ‚îÄ cedt_intern_all_merged.csv           # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
‚îú‚îÄ‚îÄ listNamePosition.csv                 # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ position IDs ‡∏ó‡∏µ‡πà‡∏à‡∏∞ bookmark
‚îî‚îÄ‚îÄ .env                                 # ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö Cookie (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ä‡∏£‡πå!)
```

## üöÄ Setup & Installation

### 1. Clone Repository
```bash
git clone https://github.com/supakornPanya/Scraping_Intern.git
cd Scraping_Intern
```

### 2. Install Dependencies
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
pip install pandas requests python-dotenv matplotlib seaborn numpy
```

‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡∏°‡∏µ `requirements.txt`:
```bash
pip install -r requirements.txt
```

### 3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variables
‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ:

```env
# .env
COOKIE=athena_session=eyJpdiI6Imae%2FfJUly485EiN%2FyIsInZhbH...
CEDT_COOKIE=athena_session=eyJpdiI6Imae%2FfJUly485EiN%2FyIsInZhbH...
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏≤ Cookie:**
1. ‡πÄ‡∏õ‡∏¥‡∏î Browser (Chrome/Brave) ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤ https://cedtintern.cp.eng.chula.ac.th
2. Login ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏ö
3. ‡∏Å‡∏î `F12` ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î DevTools
4. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà **Application** ‚Üí **Cookies** ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å site
5. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ `athena_session` ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
6. ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô `.env` ‡πÑ‡∏ü‡∏•‡πå

‚ö†Ô∏è **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: Cookie ‡∏à‡∏∞‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏≠‡∏≤‡∏ó‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ ‡∏´‡∏≤‡∏Å‡πÄ‡∏à‡∏≠ Error 401 ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó Cookie ‡πÉ‡∏´‡∏°‡πà

## üìñ Usage Guide

### Step 1: Scraping ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 - Pagination **
```python
# ‡πÄ‡∏õ‡∏¥‡∏î scraping_intern_Paginated.ipynb
# Run ‡∏ó‡∏∏‡∏Å cell ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô cedt_intern_data_paginated13.csv
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 - detail position**
```python
# ‡πÄ‡∏õ‡∏¥‡∏î scraping_intern_DetailPosition.ipynb
# ‡πÅ‡∏Å‡πâ START_ID ‡πÅ‡∏•‡∏∞ END_ID ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
# Run ‡∏ó‡∏∏‡∏Å cell
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô cedt_intern_data_{START_ID}_{END_ID}}.csv
```

### Step 2: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

```python
# ‡πÄ‡∏õ‡∏¥‡∏î clean_data.ipynb
# Run ‡∏ó‡∏∏‡∏Å cell ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö

# ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÑ‡∏î‡πâ:
# 1. ‡πÑ‡∏ü‡∏•‡πå cedt_intern_all_merged.csv - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏•‡∏ö duplicate ‡πÅ‡∏•‡πâ‡∏ß
# 2. Statistics ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
# 3. ‡πÑ‡∏ü‡∏•‡πå listNamePosition.csv - ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ position IDs ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
```

**Filter Criteria (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£):**
```python
mask = (df['student_draft_ratio'] < 2.0) & \
       (df['salary_amount'] > 200.0) & (df['salary_amount'] < 500.0) & \
       (df['work_type'] != 'Work From Home')
```

### Step 3: Bookmark ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

```python
# ‡πÄ‡∏õ‡∏¥‡∏î slect_position.ipynb
# Run ‡∏ó‡∏∏‡∏Å cell
# ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞ bookmark ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô listNamePosition.csv
```

## üîß Configuration

### ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Scraping Parameters

**scraping_intern_Paginated.ipynb:**
```python
START_PAGE = 1      # ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
END_PAGE = 13       # ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
LIMIT = 20          # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
```

**scraping_intern_DetailPosition.ipynb:**
```python
START_ID = 1000     # ID ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
END_ID = 2000       # ID ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
```

### ‡∏õ‡∏£‡∏±‡∏ö Filter Criteria (clean_data.ipynb)

```python
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç mask ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
mask = (df['student_draft_ratio'] < 2.0) & \          # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤:‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á < 2
       (df['salary_amount'] > 200.0) & \              # ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 200/‡∏ß‡∏±‡∏ô
       (df['salary_amount'] < 500.0) & \              # ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 500/‡∏ß‡∏±‡∏ô
       (df['work_type'] != 'Work From Home')          # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà WFH
```

## üìä Data Schema

**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô CSV:**
- `id` - ID ‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
- `position_title` - ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô
- `salary_amount` - ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏ö‡∏≤‡∏ó/‡∏ß‡∏±‡∏ô ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å normalize)
- `salary_type` - ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- `quota` - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö
- `inStudentDraftCount` - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à
- `student_draft_ratio` - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô draft/quota
- `work_type` - ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (On-site, Hybrid, WFH)
- `company_name` - ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
- `location` - ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

## ‚ö†Ô∏è Important Notes

1. **Cookie Expiration**: Cookie ‡∏à‡∏∞‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ Error 401 ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó Cookie ‡πÉ‡∏´‡∏°‡πà
2. **Rate Limiting**: ‡∏°‡∏µ random delay (2-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á request ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏ô block
3. **Data Privacy**: ‡∏≠‡∏¢‡πà‡∏≤‡πÅ‡∏ä‡∏£‡πå‡πÑ‡∏ü‡∏•‡πå `.env` ‡∏´‡∏£‡∏∑‡∏≠ Cookie ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
4. **API Changes**: ‡∏ñ‡πâ‡∏≤ API ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô structure ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î

## üêõ Troubleshooting

### Error 401 Unauthorized
```bash
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó Cookie ‡πÉ‡∏ô .env ‡πÑ‡∏ü‡∏•‡πå
# Cookie ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏≠‡∏≤‡∏ó‡πå
```

### ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô CSV
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:
# 1. Cookie ‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
# 2. START_PAGE/START_ID ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
# 3. Internet connection
```

### ImportError
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á package ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢
pip install [package_name]
```

## üìù License

This project is for educational purposes only.

## üë§ Author

**supakornPanya**
- GitHub: [@supakornPanya](https://github.com/supakornPanya)

---
**Happy Scraping! üöÄ**